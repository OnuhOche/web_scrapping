{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Libraries\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "import re\n",
    "from langdetect import detect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base URL\n",
    "base_url = \"http://quotes.toscrape.com/page/{}/\"\n",
    "\n",
    "# Initialize list to store results\n",
    "sentences = []\n",
    "sentence_id = 1\n",
    "\n",
    "#Import the requests library\n",
    "import requests # This line ensures that the 'requests' module is accessible\n",
    "from bs4 import BeautifulSoup # Import BeautifulSoup here\n",
    "import re # Import the 're' module for regular expressions\n",
    "\n",
    "# Loop through first 5 pages\n",
    "for page in range(1, 6):\n",
    "    response = requests.get(base_url.format(page))\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    # Find all quote elements\n",
    "    quotes = soup.find_all('span', class_='text')\n",
    "\n",
    "    for quote in quotes:\n",
    "        text = quote.get_text(strip=True)\n",
    "\n",
    "        # Clean the text: remove symbols and check length\n",
    "        clean_text = re.sub(r'[^\\w\\s.,!?]', '', text)\n",
    "        if 10 < len(clean_text) < 200:\n",
    "            try:\n",
    "                # Detect if it's English\n",
    "                if detect(clean_text) == 'en':\n",
    "                    sentences.append((sentence_id, clean_text))\n",
    "                    sentence_id += 1\n",
    "            except:\n",
    "                continue  # Skip if language detection fails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize list to store results\n",
    "sentences = []\n",
    "sentence_id = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize list to store results\n",
    "sentences = []\n",
    "sentence_id = 1\n",
    "\n",
    "# Loop through first 5 pages\n",
    "for page in range(1, 6):\n",
    "    response = requests.get(url.format(page))\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    # Find all poem elements\n",
    "    poems = soup.find_all('span', class_='text')\n",
    "\n",
    "    for poem in poems:\n",
    "        text = poem.get_text(strip=True)\n",
    "\n",
    "        # Clean the text: remove symbols and check length\n",
    "        clean_text = re.sub(r'[^\\w\\s.,!?]', '', text)\n",
    "        if 10 < len(clean_text) < 200:\n",
    "            try:\n",
    "                # Detect if it's English\n",
    "                if detect(clean_text) == 'en':\n",
    "                    sentences.append((sentence_id, clean_text))\n",
    "                    sentence_id += 1\n",
    "            except:\n",
    "                continue  # Skip if language detection fails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = [f\"http://quotes.toscrape.com/page/{page}/\", f\"https://www.ted.com/talks/susan_cain_the_power_of_introverts/transcript\"]\n",
    "sentences = []\n",
    "sentence_id = 1\n",
    "\n",
    "for page in range(1, 10):  # Loop through 5 pages\n",
    "    response = requests.get(url.format(page))\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    quotes = soup.find_all('span', class_='text')\n",
    "\n",
    "    for quote in quotes:\n",
    "        text = quote.get_text(strip=True)\n",
    "        if 10 < len(text) < 200:  # Length filtering\n",
    "            clean_text = re.sub(r'[^\\w\\s.,!?]', '', text)  # Remove strange symbols\n",
    "            try:\n",
    "                if detect(clean_text) == 'en':  # Language check\n",
    "                    sentences.append((sentence_id, clean_text))\n",
    "                    sentence_id += 1\n",
    "            except:\n",
    "                continue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>The world as we have created it is a process o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>It is our choices, Harry, that show what we tr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>There are only two ways to live your life. One...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>The person, be it gentleman or lady, who has n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Imperfection is beauty, madness is genius and ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentence_id                                               text\n",
       "0            1  The world as we have created it is a process o...\n",
       "1            2  It is our choices, Harry, that show what we tr...\n",
       "2            3  There are only two ways to live your life. One...\n",
       "3            4  The person, be it gentleman or lady, who has n...\n",
       "4            5  Imperfection is beauty, madness is genius and ..."
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(sentences, columns=['sentence_id', 'text'])\n",
    "df.to_csv('speech_dataset.csv', index=False)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lowercase, remove periods\n",
    "df['text'] = df['text'].str.lower().str.replace('.', '', regex=False)\n",
    "\n",
    "# Remove duplicates\n",
    "df.drop_duplicates(subset='text', inplace=True)\n",
    "\n",
    "# Final check\n",
    "df.to_csv('clean_speech_dataset.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final check\n",
    "df.to_csv('clean_speech_dataset.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the list\n",
    "sentences = []\n",
    "sentence_id = 1\n",
    "\n",
    "# Loop through pages 1 to 10\n",
    "for page in range(1, 10):\n",
    "    response = requests.get(f\"http://quotes.toscrape.com/page/\")\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    # Find all poem blocks\n",
    "    poem_blocks = soup.find_all('div', class_='poem')\n",
    "\n",
    "    for poem_block in poem_blocks:\n",
    "        text_span = poem_block.find('span', class_='text')\n",
    "        if text_span:\n",
    "            raw_text = text_span.get_text(strip=True)\n",
    "            clean_text = re.sub(r'[^\\w\\s.,!?]', '', raw_text)  # Remove unwanted symbols\n",
    "            if 10 < len(clean_text) < 200:\n",
    "                try:\n",
    "                    if detect(clean_text) == 'en':\n",
    "                        sentences.append((sentence_id, clean_text))\n",
    "                        sentence_id += 1\n",
    "                except:\n",
    "                    continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status Code: 200\n",
      "<!DOCTYPE html>\n",
      "<html lang=\"en\">\n",
      "<head>\n",
      "\t<meta charset=\"UTF-8\">\n",
      "\t<title>Quotes to Scrape</title>\n",
      "    <link rel=\"stylesheet\" href=\"/static/bootstrap.min.css\">\n",
      "    <link rel=\"stylesheet\" href=\"/static/main.css\">\n",
      "    \n",
      "    \n",
      "</head>\n",
      "<body>\n",
      "    <div class=\"container\">\n",
      "        <div class=\"row header-box\">\n",
      "            <div class=\"col-md-8\">\n",
      "                <h1>\n",
      "                    <a href=\"/\" style=\"text-decoration: none\">Quotes to Scrape</a>\n",
      "                </h1>\n",
      "            </div>\n",
      "            <div class=\"col-md-4\">\n",
      "                <p>\n",
      "                \n",
      "                    <a href=\"/login\">Login</a>\n",
      "                \n",
      "                </p>\n",
      "            </div>\n",
      "        </div>\n",
      "    \n",
      "\n",
      "<div class=\"row\">\n",
      "    <div class=\"col-md-8\">\n",
      "\n",
      "    <div class=\"quote\" itemscope itemtype=\"http://schema.org/CreativeWork\">\n",
      "        <span class=\"text\" itemprop=\"text\">“The world as we have created it is a process of our thinking. It cannot be changed without changing our thinking.”</span>\n",
      "        <span>by <small class=\"auth\n"
     ]
    }
   ],
   "source": [
    "response = requests.get(\"http://quotes.toscrape.com/page/1/\")\n",
    "print(\"Status Code:\", response.status_code)\n",
    "print(response.text[:1000])  # print first 1000 characters of the page\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the list\n",
    "sentences = []\n",
    "sentence_id = 1\n",
    "\n",
    "# Loop through pages 1 to 10\n",
    "for page in range(1, 10):\n",
    "    response = requests.get(f\"http://quotes.toscrape.com/page/{page}/\")\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    # Find all quote blocks\n",
    "    quote_blocks = soup.find_all('div', class_='quote')\n",
    "\n",
    "    for quote_block in quote_blocks:\n",
    "        text_span = quote_block.find('span', class_='text')\n",
    "        if text_span:\n",
    "            raw_text = text_span.get_text(strip=True)\n",
    "            clean_text = re.sub(r'[^\\w\\s.,!?]', '', raw_text)  # Remove unwanted symbols\n",
    "            if 10 < len(clean_text) < 200:\n",
    "                try:\n",
    "                    if detect(clean_text) == 'en':\n",
    "                        sentences.append((sentence_id, clean_text))\n",
    "                        sentence_id += 1\n",
    "                except:\n",
    "                    continue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of quotes found: 10\n",
      "“The world as we have created it is a process of our thinking. It cannot be changed without changing our thinking.”\n",
      "“It is our choices, Harry, that show what we truly are, far more than our abilities.”\n",
      "“There are only two ways to live your life. One is as though nothing is a miracle. The other is as though everything is a miracle.”\n",
      "“The person, be it gentleman or lady, who has not pleasure in a good novel, must be intolerably stupid.”\n",
      "“Imperfection is beauty, madness is genius and it's better to be absolutely ridiculous than absolutely boring.”\n",
      "“Try not to become a man of success. Rather become a man of value.”\n",
      "“It is better to be hated for what you are than to be loved for what you are not.”\n",
      "“I have not failed. I've just found 10,000 ways that won't work.”\n",
      "“A woman is like a tea bag; you never know how strong it is until it's in hot water.”\n",
      "“A day without sunshine is like, you know, night.”\n"
     ]
    }
   ],
   "source": [
    "url = \"http://quotes.toscrape.com/page/1/\"\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "# Try to find all quote blocks\n",
    "quote_blocks = soup.find_all('div', class_='quote')\n",
    "\n",
    "print(\"Number of quotes found:\", len(quote_blocks))\n",
    "\n",
    "for quote in quote_blocks:\n",
    "    text = quote.find('span', class_='text').get_text(strip=True)\n",
    "    print(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total sentences collected: 78\n",
      "[(1, 'The world as we have created it is a process of our thinking. It cannot be changed without changing our thinking.'), (2, 'It is our choices, Harry, that show what we truly are, far more than our abilities.'), (3, 'There are only two ways to live your life. One is as though nothing is a miracle. The other is as though everything is a miracle.'), (4, 'The person, be it gentleman or lady, who has not pleasure in a good novel, must be intolerably stupid.'), (5, 'Imperfection is beauty, madness is genius and its better to be absolutely ridiculous than absolutely boring.')]\n"
     ]
    }
   ],
   "source": [
    "sentences = []\n",
    "sentence_id = 1\n",
    "\n",
    "# Loop through pages 1 to 10\n",
    "for page in range(1, 10):\n",
    "    response = requests.get(f\"http://quotes.toscrape.com/page/{page}/\")\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    quote_blocks = soup.find_all('div', class_='quote')\n",
    "\n",
    "    for quote in quote_blocks:\n",
    "        text = quote.find('span', class_='text').get_text(strip=True)\n",
    "        clean_text = re.sub(r'[^\\w\\s.,!?]', '', text)  # Remove strange characters\n",
    "\n",
    "        if 10 < len(clean_text) < 200:\n",
    "            try:\n",
    "                if detect(clean_text) == 'en':\n",
    "                    sentences.append((sentence_id, clean_text))\n",
    "                    sentence_id += 1\n",
    "            except:\n",
    "                continue  # Skip if language detection fails\n",
    "\n",
    "# Check results\n",
    "print(f\"Total sentences collected: {len(sentences)}\")\n",
    "print(sentences[:5])  # Show first 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total sentences collected: 88\n",
      "[(1, 'The world as we have created it is a process of our thinking. It cannot be changed without changing our thinking.'), (2, 'It is our choices, Harry, that show what we truly are, far more than our abilities.'), (3, 'There are only two ways to live your life. One is as though nothing is a miracle. The other is as though everything is a miracle.'), (4, 'The person, be it gentleman or lady, who has not pleasure in a good novel, must be intolerably stupid.'), (5, 'Imperfection is beauty, madness is genius and its better to be absolutely ridiculous than absolutely boring.')]\n",
      "Saved to 'quotes_dataset.csv'\n"
     ]
    }
   ],
   "source": [
    "sentences = []\n",
    "sentence_id = 1\n",
    "\n",
    "# Loop through pages 1 to 45\n",
    "for page in range(1, 45):\n",
    "    response = requests.get(f\"http://quotes.toscrape.com/page/{page}/\")\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    quote_blocks = soup.find_all('div', class_='quote')\n",
    "\n",
    "    for quote in quote_blocks:\n",
    "        text = quote.find('span', class_='text').get_text(strip=True)\n",
    "        clean_text = re.sub(r'[^\\w\\s.,!?]', '', text)  # Remove strange characters\n",
    "\n",
    "        if 10 < len(clean_text) < 200:\n",
    "            try:\n",
    "                if detect(clean_text) == 'en':\n",
    "                    sentences.append((sentence_id, clean_text))\n",
    "                    sentence_id += 1\n",
    "            except:\n",
    "                continue  # Skip if language detection fails\n",
    "\n",
    "# Check results\n",
    "print(f\"Total sentences collected: {len(sentences)}\")\n",
    "print(sentences[:5])  # Show first 5 sentences\n",
    "\n",
    "# Save data to CSV\n",
    "df = pd.DataFrame(sentences, columns=[\"ID\", \"Sentence\"])\n",
    "df.to_csv('quotes_dataset.csv', index=False)\n",
    "\n",
    "# Print confirmation\n",
    "print(\"Saved to 'quotes_dataset.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
